## ID3算法

每次迭代选择信息增益最大的特征属性作为划分属性
$$
Ent(D) = -\sum_{k=1}^{|y|}p_k\log_{2}{p_k} \\
Gain(D,a) = Ent(D)-\sum_{v=1}^{V}\frac{|D^v|}{D}Ent(D^v)
$$
**优点**：

- 决策结构造速度快，实现简单

**缺点**:

- 计算依赖于特征数目较多的特征，而属性值最多的属性差不一定最优
- 不是递增算法
- 是单变量决策树，不考虑其他属性之前的关系
- 抗噪性差
- 只适合小规模数据集，需要将数据放到内存中



## C4.5
基于ID3,进行了优化，使用信息增益率，在树的构造过程中会进行**剪枝**操作进行优化，能够自动完成对连续属性的离散化处理，
$$
Gain\_ratio(D,a) = \frac{Gain(D,a)}{IV(a)},
\\其中,IV(a)=-\sum_{v=1}^{V}\frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}
$$
**优点**：

- 产生的规则易于理解

- 准确率较高

- 实现简单

**缺点**：

- 对数据集需要进行多次顺序扫描和排序，效率低
- 只适合小规模数据集，需要将数据放到内存中

## CART算法

使用GINI增益作为划分选择的标准，可用于分类和回归，**构建是二叉树**
$$
\
begin{align}
Gini(D)&=\sum_{k=1}^{|y|}\sum_{k'\neq{k}}p_kp_{k'}\\
&=1-\sum_{k=1}^{|y|}p_k^2
\end{align}
$$
  



